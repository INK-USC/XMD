{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a70fdf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.0034,  0.5786, -0.0594,  0.3033,  0.0268,  0.0473,  0.0849,\n",
      "          0.0083,  0.0706,  0.0644, -0.0404,  0.0910,  0.0000],\n",
      "        [ 0.0000,  0.1954, -0.5991, -0.0430, -0.3898, -0.1109, -0.0233, -0.0698,\n",
      "         -0.0522, -0.1291, -0.0948,  0.0439, -0.1306,  0.0000],\n",
      "        [ 0.0000, -0.1245, -0.0532,  0.1059,  0.0812,  0.0143,  0.0236,  0.0288,\n",
      "          0.0193,  0.0526,  0.0358,  0.0012,  0.0088,  0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "[ 0.6375017  -0.76321051  0.10536265]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>hate speech</b></text></td><td><text style=\"padding-right:2em\"><b>hate speech (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>label</b></text></td><td><text style=\"padding-right:2em\"><b>-0.02</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> all                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> muslims                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6375017  -0.76321051  0.10536265]\n"
     ]
    }
   ],
   "source": [
    "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'Hate-speech-CNERG/bert-base-uncased-hatexplain'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import InterpretableEmbeddingBase, TokenReferenceBase\n",
    "from captum.attr import visualization\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "# We need to split forward pass into two part:\n",
    "# 1) embeddings computation\n",
    "# 2) classification\n",
    "\n",
    "def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None):\n",
    "    if attention_mask is None:\n",
    "        attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n",
    "\n",
    "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    extended_attention_mask = extended_attention_mask.to(\n",
    "        dtype=next(model_bert.parameters()).dtype)  # fp16 compatibility\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "    if head_mask is not None:\n",
    "        if head_mask.dim() == 1:\n",
    "            head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "        elif head_mask.dim() == 2:\n",
    "            head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
    "        head_mask = head_mask.to(\n",
    "            dtype=next(model_bert.parameters()).dtype)  # switch to fload if need + fp16 compatibility\n",
    "    else:\n",
    "        head_mask = [None] * model_bert.config.num_hidden_layers\n",
    "\n",
    "    encoder_outputs = model_bert.encoder(embedding_output,\n",
    "                                         extended_attention_mask,\n",
    "                                         head_mask=head_mask)\n",
    "    sequence_output = encoder_outputs[0]\n",
    "    pooled_output = model_bert.pooler(sequence_output)\n",
    "    outputs = (sequence_output, pooled_output,) + encoder_outputs[\n",
    "                                                  1:]  # add hidden_states and attentions if they are here\n",
    "    return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class BertModelWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        outputs = compute_bert_outputs(self.model.bert, embeddings)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.model.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "bert_model_wrapper = BertModelWrapper(model)\n",
    "ig = IntegratedGradients(bert_model_wrapper)\n",
    "\n",
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1):\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "\n",
    "    input_ids = torch.tensor([tokenizer.encode(sentence, add_special_tokens=True)])\n",
    "    attn_mask = torch.ones(input_ids.shape[0], input_ids.shape[1]).to(input_ids)\n",
    "    number_of_class = len(list(model.config.id2label.values()))\n",
    "\n",
    "    batch_size = input_ids.shape[0]\n",
    "    input_ids = input_ids.unsqueeze(1).expand(-1, number_of_class, -1).reshape(-1, input_ids.shape[1])\n",
    "    attn_mask = attn_mask.unsqueeze(1).expand(-1, number_of_class, -1).reshape(-1, input_ids.shape[1])\n",
    "    all_classes = torch.arange(number_of_class).unsqueeze(0).expand(batch_size, -1).flatten()\n",
    "    #print(input_ids.shape, attn_mask.shape, all_classes.shape)\n",
    "    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n",
    "\n",
    "    baseline = torch.full(input_ids.shape, tokenizer.pad_token_id).long()\n",
    "    baseline[:, 0] = tokenizer.cls_token_id\n",
    "    sep_token_locs = torch.nonzero(input_ids == tokenizer.sep_token_id)\n",
    "    baseline[sep_token_locs[:, 0], sep_token_locs[:, 1]] = tokenizer.sep_token_id\n",
    "    baseline_embeds = model_wrapper.model.bert.embeddings(baseline)\n",
    "  \n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    attributions_ig = ig.attribute(inputs=input_embedding.requires_grad_(),\n",
    "                                   target=all_classes,\n",
    "                                   baselines=baseline_embeds,\n",
    "                                   n_steps=500,\n",
    "                                   )\n",
    "    \n",
    "#     pred = model_wrapper(input_embedding).item()\n",
    "#     pred_ind = round(pred)\n",
    "    attributions_ig = torch.sum(attributions_ig, dim=-1)\n",
    "    attributions_ig = attributions_ig * attn_mask\n",
    "    print(attributions_ig)\n",
    "\n",
    "    #print('pred: ', 0, '(', '%.2f'% pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].numpy().tolist())\n",
    "    add_attributions_to_visualizer(attributions_ig, tokens, 0, 0, label, 0, vis_data_records_ig)\n",
    "\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, tokens, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.detach().numpy()\n",
    "    \n",
    "    print(attributions)\n",
    "    \n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "        attributions,\n",
    "        pred,\n",
    "        list(model.config.id2label.values())[pred_ind],\n",
    "        list(model.config.id2label.values())[label],\n",
    "        \"label\",\n",
    "        attributions.sum(),\n",
    "        tokens[:len(attributions)],\n",
    "        delta))\n",
    "\n",
    "\n",
    "interpret_sentence(bert_model_wrapper, sentence=\"all muslims are terrorists and need to be deported from this country\", label=0)\n",
    "visualization.visualize_text(vis_data_records_ig)\n",
    "print(vis_data_records_ig[0].word_attributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e55aa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12ed2fb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(vis_data_records_ig[0].word_attributions[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41c04d11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0977, 0.0798, 0.0757, 0.0931, 0.0895, 0.0865, 0.0875, 0.0484, 0.0845,\n",
       "        0.0858, 0.0837, 0.0878], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a2e46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}